<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Conformal Prediction: A Visual Introduction</title>
  <script defer src="js/template.v2.js"></script>
  <script defer src="js/frog_example.js"></script>
  <script defer src="js/regression.js"></script>

  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <link rel="stylesheet" type="text/css" href="css/styles.css">
</head>

<body>

  <d-front-matter>
    <script id='distill-front-matter' type="text/json">
      {
        "title": "Conformal Prediction: A Visual Introduction",
        "description": "Uncertainty Estimation for Predictions in Machine Learning.",
        "authors": [{
            "author": "Mihir Agarwal",
            "authorURL": "link_1",
            "affiliations": [{
              "name": "Indian Insitute of Technology Gandhinagar",
              "affiliationURL": "https://www.iitgn.ac.in/"
            }]
          },
          {
            "author": "Lalit Chandra Routhu",
            "authorURL": "link_2",
            "affiliations": [{
              "name": "Indian Insitute of Technology Patna",
              "affiliationURL": "https://www.iitp.ac.in/"
            }]
          },
          {
            "author": "Zeel B Patel",
            "authorURL": "link_3",
            "affiliations": [{
              "name": "Indian Insitute of Technology Gandhinagar",
              "affiliationURL": "https://www.iitgn.ac.in/"
            }]
          },
          {
            "author": "Nipun Batra",
            "authorURL": "link_4",
            "affiliations": [{
              "name": "Indian Insitute of Technology Gandhinagar",
              "affiliationURL": "https://www.iitgn.ac.in/"
            }]
          }
        ],
        "katex": {
          "delimiters": [{
            "left": "$$",
            "right": "$$",
            "display": false
          }]
        }
      }
    </script>
  </d-front-matter>

  <d-title style="padding-bottom: 0">
    <!-- <p>Uncertainty Estimation for Predictions in Machine Learning</p> -->
  </d-title>

  <d-byline></d-byline>

  <d-article style="overflow-x: unset;">
    
    <h1>Introduction</h1>
    <p>
        Understanding the nuances of uncertainty is pivotal in numerous domains, ranging from financial forecasting to healthcare diagnostics and autonomous vehicle control. The accurate quantification of uncertainty enables robust decision-making and engenders trust in machine learning models. For instance, in medical settings, a false negative could result in untreated disease progression, while a false positive might lead to unnecessary treatments—both with life-altering implications.
    </p>

    <p> <!-- Add citation in this paragraph  -->
        To illustrate, consider a scenario where a machine learning model was fine-tuned to classify green apples and oranges. Utilizing the fast.ai<sup><a href="#References"></a></sup> library, a ResNet18 model was deployed and fed a myriad of images containing these fruits. However, when exposed to images of other objects that were green—such as frogs, green tennis balls, and even green oranges—the model overwhelmingly classified these as 'green apples' with high confidence. You can see the examples as follows:
    </p>

    <div>
        <ul><li>Select one of the three images:</li></ul>
        <div class="frog-container">
            <div class="frog-column" style="flex: 3;">
                <div class="frog-wrapper">
                    <div class="frog-section">
                        <div class="frog-image-preview selected" onclick="selectImage(0)">
                            <img src="images/frog_tennis/0.png" alt="Tennis Balls">
                            <!-- <p>Image 1</p> -->
                        </div>
                        <div class="frog-image-preview" onclick="selectImage(1)">
                            <img src="images/frog_tennis/1.png" alt="Green Colored Oranges">
                            <!-- <p>Image 2</p> -->
                        </div>
                        <div class="frog-image-preview" onclick="selectImage(2)">
                            <img src="images/frog_tennis/2.png" alt="Frog">
                            <!-- <p>Image 3</p> -->
                        </div>
                    </div>
                    <div class="frog-section">
                        <div class="frog-result">
                            <div class="frog-image-container">
                                <img id="frog-result-image" src="images/frog_tennis/example0.svg" alt="Result Image" style="max-width: 100%;">
                            </div>
                            <div id="frog-result-text">
                                <!-- Result text will be updated dynamically -->
                                The model assigns a high probability to categorize this tennis ball as a green apple due to its resemblance in both shape and color. However, this is an incorrect classification, and it is essential to incorporate a level of uncertainty into this prediction.
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <p> <!-- Add citation in this paragraph  -->
        This example vividly illustrates the pitfalls of biased training and the lack of uncertainty quantification. A traditional classification model would provide point estimates—single labels with associated probabilities—that could be misleading. Such deterministic outputs can have far-reaching consequences, from flawed recommendations to incorrect automated decisions.
    </p>

    <p>
        Conformal Prediction is an efficacious framework in machine learning that delivers well-calibrated measures of uncertainty associated with predictions. It extends beyond the provision of mere point estimates, constructing prediction intervals that encapsulate the realm of plausible outcomes.
    </p>

    <p>
        The absence of uncertainty quantification in many machine learning models, especially neural networks, presents obstacles in decision-making processes and undermines trustworthiness. It is imperative, therefore, to comprehend and assess the confidence level of a model’s predictions.
    </p>

    <p>
        Conformal Prediction is both robust and computationally efficient, eliminating the need for data or model-specific assumptions. Its computational complexity can be as low as O(n), outperforming Bayesian methods like MC Dropout.
    </p>

    <p>
        For any test sample \((\hat{X}_{n+1}, \hat{Y}_{n+1})\), the calculated uncertainty bands will satisfy the following property:
    </p>

    <p align = "center">
        \[
        \quad P(\hat{Y}_{n+1} \in \hat{C}(X_{n+1})) \geq 1 - \alpha
        \]
    </p>

    <p>
        This means that with probability at least \(1 - \alpha\), the computed uncertainty band \(\hat{\mathcal{X}}_{n+1}\) and \(\hat{C}(x_{n+1})\) around the point estimate \(\hat{x}_{n+1}\) and \(\hat{y}_{n+1}\) will contain the true unknown value \(x_{n+1}\) and \(y_{n+1}\). Here, \(\alpha\) is a user-chosen error rate.
        <br>
        This mathematical guarantee on prediction intervals makes it invaluable in mission-critical applications.
    </p>

    <h3>
        How Conformal Prediction Works
    </h3>

    <p>
        <ol>
            <li><strong>Data Split:</strong> Divide data into a Training and a Calibration Set.</li>
            <li><strong>Model Training:</strong> Train your model on the Training Set.</li>
            <li><strong>Scoring Rule:</strong> Create a rule to evaluate model predictions.</li>
            <li><strong>Calibration:</strong> Fine-tune the model on the Calibration Set.</li>
            <li><strong>Confidence Level:</strong> Set a desired confidence level.</li>
            <li><strong>Future Predictions:</strong> Make new predictions with confidence levels.</li>
        </ol>
    </p>

    <h1>
        Conformal Prediction for Regression
    </h1>

    <p>
        In conformal prediction for regression, we aim to construct prediction intervals around our point estimates to offer a statistically valid level of confidence. The method leverages a calibration dataset to compute 'conformity scores,' which help us rank how well the model's predictions align with actual outcomes. These scores, in turn, guide the creation of prediction intervals with a desired coverage probability. Thus, conformal prediction serves as a tool for robust and interpretable prediction intervals.
    </p>

    <p> <!-- Add citation in this paragraph  -->
        Alan Turing, often considered the father of modern computing, was also a formidable athlete. He completed a marathon—covering a distance of 26 miles and 385 yards—in just 2 hours, 46 minutes, and 3 seconds[5]. This performance equates to an impressive pace of approximately 3.94 minutes per kilometer. Utilizing conformal prediction, we aim to estimate whether Turing would have won a hypothetical Olympic gold medal in the marathon had the Olympics been held in 1946. Let's see if he wins the medal.
    </p>

    <img src = "images/newspaper_cutting.png">
    <p style="color:grey; font-size:14px; text-align:center;">Figure: Newspaper Clipping of Alan Turing\'s Marathon time,
    <a href="https://www.turing.org.uk/book/update/part6.html" style="color:grey; font-size:14px;">Source: Alan Turing Internet Scrapbook</a></p>

    <p> <!-- Add citation in this paragraph  -->
        This dataset captures the pace of Olympic Gold Medal Marathon winners from 1896 to the present. The 1904 outlier is due to organizational issues. The objective is to model and understand the trend over the years.
    </p>

    <h3>
        Model
    </h3>

    <p>
        The model, which is a Multi Layer Perceptron (MLP), will be trained on the training data and used to generate predictions on the calibration data.<br>
        The calibration data is used to estimate the quantiles (\(q_{\text{val}}\)) for the prediction intervals. You can choose the number of calibration data points (\(n\)) using the slider below.
    </p>

    <div>
        <!-- Slider for n_cal -->
        <div class="gif-slider">
            <div align="center"> Number of Calibration points: <span id="slider-value">14<br></span></div>
            <div class="controls">
                <!-- Left button for decreasing n_cal -->
                <div>
                    <button onclick="changeSlider(this.parentNode.parentNode, false, 'n_cal')">
                        <!-- Left-pointing triangle icon -->
                        <svg width="10" height="10" viewBox="0 0 10 10" style="margin-top: 3px; margin-left: -1px;">
                            <path d="M 10 0 L 0 5 L 10 10 z" fill="#888"></path>
                        </svg>
                    </button>
                </div>
                <div class="slidecontainer">
                    <!-- Display current value of n_cal above the slider -->
                    <!-- Slider input for n_cal, with defined range and step, and an event handler to update the value -->
                    <input type="range" min="10" max="20" step="2" value="14" class="slider" oninput="updateSliderValue(this.value);">
                </div>
                <!-- Right button for increasing n_cal -->
                <div>
                    <button onclick="changeSlider(this.parentNode.parentNode, true, 'n_cal')">
                        <!-- Right-pointing triangle icon -->
                        <svg width="10" height="10" viewBox="0 0 10 10" style="margin-top: 3px;">
                            <path d="M 0 0 L 10 5 L 0 10 z" fill="#888"></path>
                        </svg>
                    </button>
                </div>
            </div>
            <!-- Display the image corresponding to n_cal, with a 40% reduction in size -->
            <img src="images/Generated_Images/Regression_Prediction_Plot_14.png" id="calib-display" style="width: 95%; height: auto;">
        </div>
    
        <p align = "center">
            \[
            s_i = |y_i - \hat{y}_i|
            \]
        </p>
    
        <p>
            The score function \(s_i\) represents the absolute difference between the true output \(y_i\) and the model's predicted output \(\hat{y}_i\) for each calibration data point \(x_i\). It measures the discrepancy between the true values and their corresponding predictions, providing a measure of model fit to the calibration data.
        </p>
    
        <p>
            Use the below slider to choose the error rate \(\alpha\). With probability \(1 - \alpha\), our computed uncertainty band \(\hat{\mathcal{C}}(\hat{x}_{n+1})\) will contain the true value \(\hat{y}_{n+1}\).
        </p>
    

        <!-- Slider for alpha -->
        <div class="gif-slider">
            <div align="center"> Value of \(\alpha\) :  <span id="alpha-slider-value">0.4<br></span></div>
            <div class="controls">
                <!-- Left button for decreasing alpha -->
                <div>
                    <button onclick="changeAlpha(this.parentNode.parentNode, false)">
                        <!-- Left-pointing triangle icon -->
                        <svg width="10" height="10" viewBox="0 0 10 10" style="margin-top: 3px; margin-left: -1px;">
                            <path d="M 10 0 L 0 5 L 10 10 z" fill="#888"></path>
                        </svg>
                    </button>
                </div>
                <div class="slidecontainer">
                    <!-- Display current value of alpha above the slider -->
                    
                    <!-- Slider input for alpha, with defined range and step, and an event handler to update the value -->
                    <input type="range" min="0.1" max="1.0" step="0.1" value="0.4" class="slider" oninput="updateAlphaValue(this.value);">
                </div>
                <!-- Right button for increasing alpha -->
                <div>
                    <button onclick="changeAlpha(this.parentNode.parentNode, true)">
                        <!-- Right-pointing triangle icon -->
                        <svg width="10" height="10" viewBox="0 0 10 10" style="margin-top: 3px;">
                            <path d="M 0 0 L 10 5 L 0 10 z" fill="#888"></path>
                        </svg>
                    </button>
                </div>
            </div>
            <!-- Display the image corresponding to alpha, with a 40% reduction in size -->
            <img src="images/Generated_Images/Regression_Histogram_plot_14_for_0.4.png" id="alpha-image-display" style="width: 95%; height: auto;">
        </div>
    </div>

    <p>
        We compute \(q_{\text{val}}\) by calculating the \(\lceil \frac{(n+1)(1-\alpha)}{n} \rceil\)th quantile of the conformity scores.
    </p>
    <p align="center">
        \(q_{\text{val}} = \) <span id = "regression_qval">0.3545</span>
    </p>

    <p>
        The model predicts that the time for the Olympic gold medalist in 1946 would have been <span id = "predicted-time">3.28</span> minutes. 
        With a significance level of \(\alpha = \) <span id="significance-level">0.40</span>, the uncertainty band calculated using conformal prediction ranges from <span id = "time-lower_bound">2.92</span> to <span id = "time-upper_bound">3.63</span> minutes. <br>
        Therefore, based on this model, Alan Turing would have won the gold medal.
    </p>

    <h1>
        Conformal Prediction for Classification
    </h1>

    <p>
        In the realm of regression analysis, the model generates continuous uncertainty bands around the predicted values, offering an interval estimation of the output variable. However, as we transition to classification problems, the nature of the output changes substantively. In classification, the model generates discrete outputs, which are class probabilities. The prediction set now takes the form of a discrete subset of the available classes, mathematically represented as:
    </p>

    <p align = "center">
        \( \hat{C}(X_{n+1}) \subseteq \{1, \ldots, K\} \)
    </p>

    <p>
        In this formalism, \( \hat{C}(X_{n+1}) \) is the prediction set corresponding to a new input \( \hat{X}_{n+1} \), and \( K \) signifies the total number of unique classes.
    </p>

    <p>
        We will use the MNIST dataset. The 60,000 training samples are split into two parts: the training set, which consists of 59950 images, and the calibration set, which has 50 images. The test set consists of 10k images. For training, we will use a simple Multi-layer Perceptron. The test accuracy of the model is <b>0.912</b>.
    </p>

    <h3>
        How to calculate conformity scores?
    </h3>

    <p>
        The method of calculating conformity scores is a modelling decision. Here, we will use a simple method based on the softmax scores. The score is calculated by the following formula:
    </p>

    <p>
        \[ s_i = 1 - \hat{\pi}_{x_i}(y_i) \]
    </p>

    <p>
        For a sample \((x_i, y_i)\) from the calibration set, where \(\hat{\pi}_{x_i}(y_i)\) represents the softmax score of the true class \((y_i)\), the sample score \(s_i\) is equal to \(1\) minus the softmax output of the true class. If the softmax value of the true class is low, it means that the model is uncertain. The score in such a case will be high.
    </p>

    <p>
        After calculating the scores from the calibration set, we choose an error rate \(\alpha\). The probability that the prediction set contains the correct class will be approximately \(1 - \alpha\). If \(\alpha = 0.05\), then the probability that the prediction set contains the true class is \(0.95\).
    </p>

    <p>
        We will get the prediction set for a test sample \((\hat{x}_{n+1}, \hat{y}_{n+1})\) \((x_{n+1}, y_{n+1})\) by:
    </p>
    <p>
        \[
        \hat{\mathcal{C}}(x_{n+1}) = \left\{ y' \in \mathcal{K} : \hat{\pi}_{x_{n+1}}(y') \geq 1 - q_{\text{val}} \right\}
        \]
    </p>

    <p>
        The prediction set \(C\) consists of all the classes for which the softmax score is above a threshold value \(1 - q_{\text{val}}\). \(q_{\text{val}}\) is calculated as the \(\lceil \frac{(n+1)(1-\alpha)}{n} \rceil\)-th quantile of the scores from the calibration set.
    </p>

    <p>
        <ul><li>Alpha Slider and Histogram Plot</li></ul>
    </p>

    <p>
        For this value of \(\alpha\), the threshold value \(1 - q_{\text{val}}\) is {}.
    </p>

    <h3>
        Understanding the Predicted Set
    </h3>

    <p>
        The 'predicted set' refers to the set of classes that the model deems probable for the given input. A class is included in the predicted set if its softmax score is above a predetermined threshold. This threshold is influenced by the selected value of alpha and the computed quantile from the calibration data. The predicted set gives us an indication of the model's confidence in its classification. If the set contains multiple classes, it indicates that the model is less certain about the true class label.
    </p>

    <p>
        For example, select an image from the below slider. The softmax scores for the classes can be seen in the plot on the right side. If the score is above the threshold value, then the class is in the predicted set.
    </p>

    <p>
        <ul><li>Image Selector and Predictions</li></ul>
    </p>

    <p>
        Prediction Set for this image: {}
    </p>

    <p>
        In the above examples, the first 2 images are sourced from the Fashion-MNIST dataset. The model is uncertain about these images, which can be seen by the larger predicted set sizes. This is a property we want, as the size of the predicted set indicates the model's uncertainty. In contrast, for the last 2 images, the predicted set contains only one element because the model is confident about its prediction. This is reflected by the high softmax scores of the true classes.
    </p>

    <p>
        The average size of prediction sets for all the images from the test set is {}
    </p>

    <p>
        <b>What does the average size mean?</b><br>
        We observe that the average size of the prediction set decreases when value of alpha is increased. This is because of our method for computing conformity scores, where we only take into account the softmax scores of the correct class when calculating \(\hat{q}\). With increasing alpha, the softmax scores for the classes decreases and thus there are lesser scores above the threshold value.
    </p>

    <h1>
        Conclusion
    </h1>   
    <p>
        As we navigated the complexities and intricacies of Conformal Prediction, what emerged is a technique that is not just innovative but foundational to modern machine learning practices. Its distinctive characteristics—ranging from applicability in high-stakes domains to its model-agnostic nature—demonstrate its potential to revolutionize the way we think about, and apply, machine learning.
    </p>

    <h3>
        Implications in High-Stakes Domains
    </h3>
    <p>
        Conformal Prediction isn't merely a theoretical novelty; its implications are deeply impactful, particularly in sectors where prediction reliability is paramount, such as medical diagnostics, autonomous vehicles, and finance. Traditional machine learning methods often supply a point estimate without a gauge of prediction uncertainty. However, in life-critical applications like diagnosing illnesses, a mere point estimate is insufficient; medical practitioners require a measure of certainty accompanying each diagnosis.
    </p>

    <h3>
        Model-Agnostic Nature
    </h3>
    <p>
        One of the most salient features of Conformal Prediction is its model-agnosticism. This is a breakthrough for the ML community, which often struggles with integrating uncertainty quantification techniques that are specific to particular types of models. The model-agnosticism of Conformal Prediction means that it can be applied across various machine learning algorithms without needing algorithm-specific tuning. This is not only computationally efficient but also invaluable for researchers who may be dealing with multiple types of models.
    </p>
    
    <h3>
        Data Distribution Independence
    </h3>
    <p>
        Conformal Prediction doesn't make strong assumptions about the data distribution, making it robust in the face of non-ideal or 'dirty' data, often encountered in real-world applications. This characteristic facilitates its application in diverse industries without the need for extensive data preprocessing or assumption validations.
    </p>

  </d-article>

  <d-appendix>
    <d-bibliography src="references.bib"></d-bibliography>
  </d-appendix>

</body>
</html>
